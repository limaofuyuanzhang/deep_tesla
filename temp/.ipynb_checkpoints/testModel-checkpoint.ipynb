{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10, 28, 28, 1)\n",
      "10 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lintao/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
      "/Users/lintao/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/Users/lintao/anaconda/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s - loss: 2.3486 - acc: 0.1000 - val_loss: 2.3040 - val_acc: 0.0800\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 1\n",
    "# 输入图像的维度，此处是mnist图像，因此是28*28\n",
    "img_rows, img_cols = 28, 28\n",
    "# 卷积层中使用的卷积核的个数\n",
    "nb_filters = 32\n",
    "# 池化层操作的范围\n",
    "pool_size = (2,2)\n",
    "# 卷积核的大小\n",
    "kernel_size = (3,3)\n",
    "# keras中的mnist数据集已经被划分成了60,000个训练集，10,000个测试集的形式，按以下格式调用即可\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:10]\n",
    "y_train = y_train[:10]\n",
    "\n",
    "# 后端使用tensorflow时，即tf模式下，\n",
    "# 会将100张RGB三通道的16*32彩色图表示为(100,16,32,3)，\n",
    "# 第一个维度是样本维，表示样本的数目，\n",
    "# 第二和第三个维度是高和宽，\n",
    "# 最后一个维度是通道维，表示颜色通道数\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "# 将X_train, X_test的数据格式转为float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 打印出相关信息\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# 将类别向量(从0到nb_classes的整数向量)映射为二值类别矩阵，\n",
    "# 相当于将向量用one-hot重新编码\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "# 建立序贯模型\n",
    "model = Sequential()\n",
    "\n",
    "# 卷积层，对二维输入进行滑动窗卷积\n",
    "# 当使用该层为第一层时，应提供input_shape参数，在tf模式中，通道维位于第三个位置\n",
    "# border_mode：边界模式，为\"valid\",\"same\"或\"full\"，即图像外的边缘点是补0\n",
    "# 还是补成相同像素，或者是补1\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0] ,kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 卷积层，激活函数是ReLu\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 池化层，选用Maxpooling，给定pool_size，dropout比例为0.25\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten层，把多维输入进行一维化，常用在卷积层到全连接层的过渡\n",
    "model.add(Flatten())\n",
    "\n",
    "# 包含128个神经元的全连接层，激活函数为ReLu，dropout比例为0.5\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 包含10个神经元的输出层，激活函数为Softmax\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 输出模型的参数信息\n",
    "model.summary()\n",
    "# 配置模型的学习过程\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "# 训练模型\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# 按batch计算在某些输入数据上模型的误差\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "model.save_weights('model.h5')\n",
    "with open('model.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't decrement id ref count (Unable to extend file properly, errno = 28, error message = 'no space left on device')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9adabf5d88fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lintao/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5i.pyx\u001b[0m in \u001b[0;36mh5py.h5i.dec_ref (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/h5i.c:2497)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't decrement id ref count (Unable to extend file properly, errno = 28, error message = 'no space left on device')"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "h5_path = 'deep_tesla1.hdf5'\n",
    "if os.path.exists(h5_path):\n",
    "    os.remove(h5_path)\n",
    "\n",
    "f = h5py.File(h5_path, \"w\")\n",
    "lenth = 24300\n",
    "\n",
    "images = f.create_dataset('image', (lenth,720,1280,3), dtype='float32')\n",
    "landmark = f.create_dataset('landmark', (lenth,), dtype='float32')\n",
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "image_index = 0\n",
    "landmark_index = 0\n",
    "for i in range(1, 2):\n",
    "    # 读取转向角度\n",
    "    y_train_original = []\n",
    "    pathY = '../epochs/epoch0' + str(i) + '_steering.csv'\n",
    "    wheel_sig = pd.read_csv(pathY)\n",
    "    y_train_original.extend(wheel_sig['wheel'].values)\n",
    "    length = len(y_train_original)\n",
    "    f['landmark'][landmark_index:landmark_index+length] = y_train_original\n",
    "    landmark_index+=len(y_train_original)\n",
    " \n",
    "    # 读取图片\n",
    "    pathX = '../epochs/epoch0' + str(i) + '_front.mkv'\n",
    "    cap = cv2.VideoCapture(pathX)\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if(ret and image_index < 3):\n",
    "            f['image'][image_index] = img\n",
    "            image_index += 1\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "del images\n",
    "del landmark\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'deep_tesla.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-03b9678a2e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"deep_tesla.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmark'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lintao/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lintao/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/h5f.c:2123)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'deep_tesla.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"deep_tesla.hdf5\", \"r\")\n",
    "f['landmark'][0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Truncated file: eof = 33276944, sblock->base_addr = 0, stored_eoa = 268738659344)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-17d0ba9d5387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"deep_tesla.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lintao/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lintao/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/Users/ilan/minonda/conda-bld/h5py_1496887972496/work/h5py/h5f.c:2123)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Truncated file: eof = 33276944, sblock->base_addr = 0, stored_eoa = 268738659344)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "f = h5py.File(\"deep_tesla.hdf5\", \"r\")\n",
    "img = f['image'][0]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vgg16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "import params\n",
    "\n",
    "model_file = './models/vgg16-model.h5'\n",
    "weights_file = './models/vgg16-model.json'\n",
    "\n",
    "model\n",
    "if os.path.exists(model_file) and os.path.exists(weights_file):\n",
    "    model = model_from_json(model_file)  \n",
    "    model.load_weights(weights_file)\n",
    "else\n",
    "    #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "    shape = (params.FLAGS.img_h, params.FLAGS.img_w, params.FLAGS.img_c)\n",
    "    inputs = Input(shape=shape)\n",
    "    x=Lambda(lambda x:x/255.0-0.5)(inputs)\n",
    "    model_vgg16_conv = VGG16(include_top=False,input_shape=shape)\n",
    "    x=model_vgg16_conv(x)\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(1164, activation='relu')(x)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    x=Dense(50, activation='relu')(x)\n",
    "    x=Dense(10, activation='relu')(x)\n",
    "    outputs=Dense(1, activation='tanh')(x)\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    # model = make_parallel(model, 2)\n",
    "    model.compile(optimizer=optimizers.Adadelta(),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])\n",
    "    model.fit(x=X_train,y=y_train,epochs=20,validation_split=0.2)\n",
    "    model.save_weights(weights_file)\n",
    "    with open(model_file, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "test_loss= model.evaluate(X_test, y_test)\n",
    "print('Test loss is:{}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inc3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "model_file = './models/inceptionv3-model.h5'\n",
    "weights_file = './models/inceptionv3-model.json'\n",
    "\n",
    "model\n",
    "if os.path.exists(model_file) and os.path.exists(weights_file):\n",
    "    model = model_from_json(model_file)  \n",
    "    model.load_weights(weights_file)\n",
    "else\n",
    "    #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "    shape = (params.FLAGS.img_h, params.FLAGS.img_w, params.FLAGS.img_c)\n",
    "    inputs = Input(shape=shape)\n",
    "    x=Lambda(lambda x:x/255.0-0.5)(inputs)\n",
    "    model_inception_v3 = InceptionV3(weights='imagenet', include_top=False,input_shape=shape)\n",
    "    x=model_inception_v3(x)\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(512, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(256, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(64, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    outputs=Dense(1, activation='tanh')(x)\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    # model = make_parallel(model, 2)\n",
    "    model.compile(optimizer=optimizers.Adadelta(),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])\n",
    "    model.fit(x=X_train,y=y_train,epochs=10,validation_split=0.2)\n",
    "    model.save_weights(weights_file)\n",
    "    with open(model_file, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "test_loss= model.evaluate(X_test, y_test)\n",
    "print('Test loss is:{}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "model_file = './models/resnet50-model.h5'\n",
    "weights_file = './models/resnet50-model.json'\n",
    "\n",
    "model\n",
    "if os.path.exists(model_file) and os.path.exists(weights_file):\n",
    "    model = model_from_json(model_file)  \n",
    "    model.load_weights(weights_file)\n",
    "else\n",
    "    #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "    shape = (params.FLAGS.img_h, params.FLAGS.img_w, params.FLAGS.img_c)\n",
    "    inputs = Input(shape=shape)\n",
    "    x=Lambda(lambda x:x/255.0-0.5)(inputs)\n",
    "    model_inception_v3 = InceptionV3(weights='imagenet', include_top=False,input_shape=shape)\n",
    "    x=model_inception_v3(x)\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(512, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(256, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(64, activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    outputs=Dense(1, activation='tanh')(x)\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    # model = make_parallel(model, 2)\n",
    "    model.compile(optimizer=optimizers.Adadelta(),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])\n",
    "    model.fit(x=X_train,y=y_train,epochs=10,validation_split=0.2)\n",
    "    model.save_weights(weights_file)\n",
    "    with open(model_file, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "test_loss= model.evaluate(X_test, y_test)\n",
    "print('Test loss is:{}'.format(test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
